{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework 01 - Instructions\n",
    "\n",
    "- The goal for this lab will be to collect some data from you and get you some experience in working with Github and Jupyter Notebooks. We are going to also learn the basics of loading data into Python.\n",
    "- We will go over importing data from a number of different file types.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing a CSV File\n",
    "- This is obviously a very common technique which we will use over and over.  Luckily, someone has written a `csv` package that does the majority of the heavy lifting. \n",
    "- `import csv` imports all methods in the csv package.  \n",
    "- We are going to import the values from the csv into a specific type of Python data structure, a `list`. Declaring `listcsv=[]` initializes the objects as a list and makes available the `append` method.  \n",
    "- By using the `with open` syntax shown below, we don't have to open and then close the data structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CSV\n",
    "- Comma delimited files are a common way of transmitting data. \n",
    "- Data for different columns is separated by a comma.\n",
    "- Open the CSV file in a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing a CSV File\n",
    "- The `open` command specifies the file name and what we want to do with it, here `r` stand for read.\n",
    "- The `csvreader` is an object which iterates on the file. \n",
    "- We then read each `row` using a `for` loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example of how to import a CSV into a Python list. \n",
    "import csv  #This imports the CSV package.\n",
    "listcsv=[] #This initializes a list data structure.\n",
    "\n",
    "with open('in/name.csv', 'r') as data_file:   #The \"with\" incorporates an open and close of file. \n",
    "    csvreader = csv.reader(data_file, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        print(\"each row of the reader imported as a:\", type(row), row,\"\\n\")\n",
    "        listcsv.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reassigning variables programiatically. \n",
    "- `listcsv` is a 2 dimensional list, with the first number indicating the row and the second number indicating the column.\n",
    "- Objects start numbering at 0, so that in this case the header-row is 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q1. Updated ALL values of list  (with your infoormation) (1 pt).\n",
    "#Here is how you update your list.  Updated ALL values.  \n",
    "listcsv[1][1] = \"your first\"   #row/column numbers start at 0\n",
    "listcsv[1][2] = \"your last\"    #row/column numbers start at 0\n",
    "#...(update the rest of the variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Output the CSV File\n",
    "- Here, notice we are doing just the same thing as reading. However, we are doing it by opening with a `w`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we are going to save as a tab delimited file\n",
    "with open(\"out/name.csv\", 'w' ) as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    writer.writerows(listcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Writing a Tab Delimited file\n",
    "- Here we are able to output the file as a tab delimited file.  \n",
    "- A tab delimed file utilizes '\\t' as the delimiter.\n",
    "- Update the file below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we are going to save as a tab delimited file\n",
    "with open(\"out/name.txt\", 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter='\\t')\n",
    "    writer.writerows(listcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing CSV into a Pandas Dataframe\n",
    "- Data structured like CSV's is extremely common\n",
    "- We are going to use a special package called Pandas which will give access to many useful methods for working with data.  \n",
    "- `pandas` is often imported as the abbreviated `pd`.\n",
    "- Typing the object name of a pandas dataframe (here `dfcsv`) gives a *pretty printed* version of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load the local name.csv file into a Pandas dataframe.  We will work with these a lot in the future.\n",
    "import pandas as pd # This line imports the pandas package. \n",
    "dfcsv = pd.read_csv('in/name.csv')\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the Pandas Magic! \n",
    "- Pandas figured out that you have columns and even knows the rows. \n",
    "- We can update the files via loc or i-loc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have 2 ways of updating the file. First \n",
    "dfcsv.loc[0, 'first-name'] = 'your first via loc'\n",
    "dfcsv.loc[0, 'last-name'] = 'your last via loc'\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just utilizes the integer position. \n",
    "dfcsv.iloc[0, 0] = 'your first via iloc'\n",
    "dfcsv.iloc[0, 1] = 'your last via iloc'\n",
    "dfcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the remainder of the information using the loc method of Pandas. \n",
    "# Notice how we can just as easily write the file. \n",
    "dfcsv = dfcsv.to_csv('out/namepd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "- Javascript object notation.  \n",
    "- This enables multipled layers of nesting, something that could take multiple files in a CSV or relational tables.\n",
    "- JSON is often used for APIs.\n",
    "- Our JSON is imported as a `dictionary`, which is another internal type of Python data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json   #This imports the JSON\n",
    "from pprint import pprint  #This will print the file in a nested way. \n",
    "\n",
    "with open('in/name.json') as data_file:   #The \"with\" incorporates an open and close of file.   \n",
    "    datajson = json.load(data_file)\n",
    "\n",
    "print(\"data is a python object of type: \", type(datajson),\"\\n\")\n",
    "pprint(datajson) #Pretty printing (pprint) makes it easier to see the nesting of the files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how you update the dictionary: \n",
    "#We are indicating that we want the first student, and from there we list which \"key\" for \n",
    "#the dictionary we want (i.e., 'first-name').\n",
    "# Update the rest of the information with your \n",
    "\n",
    "datajson['student'][0]['first-name']  = 'Your first name'\n",
    "datajson['student'][0]['last-name']  = 'your last name'\n",
    "pprint(datajson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json   #This imports the JSON\n",
    "from pprint import pprint  #This will print the file in a nested way. \n",
    "\n",
    "with open('out/name.json', 'w') as data_file:   #The \"with\" incorporates an open and close of file.   \n",
    "    json.dump(datajson, data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parquet Files\n",
    "- CSV files are great for humans to read and understand.  \n",
    "- For \"big data\" though, it isn't a great long term storage option (inefficient/slow).\n",
    "- Parquet is a type columnar storage format.  It makes dealing with lots of columns fast. \n",
    "- [fastparquet](https://fastparquet.readthedocs.io) is a Python package for dealing with Parquet files. \n",
    "- Apache Spark also natively reads Parquet Files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastparquet import ParquetFile\n",
    "pf = ParquetFile('in/name.parq')\n",
    "dfparq = pf.to_pandas()\n",
    "dfparq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the dfparq dataframe (same code as Pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can similarly easily write to a .parq file. \n",
    "from fastparquet import write\n",
    "write('out/name.parq', dfparq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Rubric\n",
    "The following Rubric will be used to grade homwork. \n",
    "q1. Updated `out/name.csv` file with your infoormation  (2 pt).<br>\n",
    "q2. Updated `out/name.txt` file with your infoormation  (2 pt).<br>\n",
    "q3. Updated `out/name.csv` file with your infoormation  (2 pt).<br>\n",
    "q4. Updated `out/name.json`  file with your infoormation  (2 pt).<br>\n",
    "q5. Updated `out/name.parq` parquet file (2 pt)<br>\n",
    "q6. Review the [pandas documentation](https://pandas.pydata.org) and descripe 3 cool things that Pandas can do.  (2 pt) <br>\n",
    "q7. Describe the difference between the loc and iloc with accessing a Pandas dataframe. \n",
    "q8. Let's say you had this sample data in json.  Show (conceptually) how you would go about changing this to a CSV file. Your output should just list the structure of the data file. \n",
    "```{json}\n",
    "myObj = {\n",
    "    \"name\":\"John\",\n",
    "    \"age\":30,\n",
    "    \"cars\": {\n",
    "        \"car1\":\"Ford\",\n",
    "        \"car2\":\"BMW\",\n",
    "        \"car3\":\"Fiat\"\n",
    "    }\n",
    " }\n",
    "\n",
    "```\n",
    "q9.  Read through the [fastparquet documentation](https://fastparquet.readthedocs.io) \n",
    "q10. Agreement with statement: \"I work through this entire homework step by step.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Notice how we can use 3 quotes. \n",
    "q6 = \"\"\"q6.  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q7 = \"\"\"q7.\n",
    "Enter answer here. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q8 = \"\"\"q8.\n",
    "Enter answer here. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q9 = \"\"\"q9.\n",
    "Enter answer here. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q10 I work throug this entire homework step by step. Change to True if you did. \n",
    "\n",
    "q10= \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers= [q6,q7,q8,q9,q10]\n",
    "with open('out/answers.txt', 'w') as outfile:   #The \"with\" incorporates an open and close of file. \n",
    "    outfile.write(\"\\n\".join(answers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This work is licensed under the [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/) license agreement."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "environment": "py3k",
   "summary": "A test Jupyter notebook to verify local Python Environment.",
   "url": "https://anaconda.org/analyticsdojo/local-intro"
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
